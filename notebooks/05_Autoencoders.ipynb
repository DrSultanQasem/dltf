{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 05 Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Introduction to Autoencoders and Applications\n",
    "- Autoencoder Structure\n",
    "- Deep Belief Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Autoencoders and Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/01_Intro/04_models/14_autoencoder.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/01_Intro/04_models/15_autoencoder_apps.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/05_Autoencoders/01_Intro/01_problem_1.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/05_Autoencoders/01_Intro/02_problem_2.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/05_Autoencoders/01_Intro/03_autoencoder.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/05_Autoencoders/01_Intro/04_apps.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/05_Autoencoders/01_Intro/05_curse_of_dimensionality.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/05_Autoencoders/01_Intro/06_sparsity.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/05_Autoencoders/01_Intro/07_autoencoder_vs_pca_1.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/05_Autoencoders/01_Intro/08_autoencoder_vs_pca_2.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autoencoder Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/05_Autoencoders/02_learning/01_autoencoder_1.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/05_Autoencoders/02_learning/02_autoencoder_2.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/05_Autoencoders/02_learning/03_autoencoder_3.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/05_Autoencoders/02_learning/04_autoencoder_vs_rbm.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/05_Autoencoders/02_learning/05_architecture.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/05_Autoencoders/02_learning/06_learning_process.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/no7omt2jhqvv7uuls7ihnzikyl9ysnfp.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An autoencoder can be divided in two parts, the <b>encoder</b> and the <b>decoder</b>.\n",
    "\n",
    "The encoder needs to compress the representation of an input. In this case we are going to reduce the dimension the face of our actor, from 2000 dimensions to only 30 dimensions, by running the data through layers of our encoder.\n",
    "\n",
    "The decoder works like encoder network in reverse. It works to recreate the input, as closely as possible. This plays an important role during training, because it forces the autoencoder to select the most important features in the compressed representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"ref4\"></a>\n",
    "<h2>Performance</h2>\n",
    "\n",
    "After the training has been done, you can use the encoded data as a reliable dimensionally-reduced data, applying it to any problems where dimensionality reduction seems appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/yt3xyon4g2jyw1w9qup1mvx7cgh28l64.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This image was extracted from the G. E. Hinton and R. R. Salakhutdinovcomparing's <a href=\"https://www.cs.toronto.edu/~hinton/science.pdf\">paper</a>, on the two-dimensional reduction for 500 digits of the MNIST, with PCA on the left and autoencoder on the right. We can see that the autoencoder provided us with a better separation of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"ref5\"></a>\n",
    "<h2>Training: Loss function</h2>\n",
    "\n",
    "An autoencoder uses the Loss function to properly train the network. The Loss function will calculate the differences between our output and the expected results. After that, we can minimize this error with gradient descent. There are more than one type of Loss function, it depends on the type of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Binary Values:</h3>\n",
    "$$l(f(x)) = - \\sum_{k} (x_k log(\\hat{x}_k) + (1 - x_k) \\log (1 - \\hat{x}_k) \\ )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For binary values, we can use an equation based on the sum of Bernoulli's cross-entropy. \n",
    "\n",
    "$x_k$ is one of our inputs and $\\hat{x}_k$ is the respective output.\n",
    "\n",
    "We use this function so that if $x_k$ equals to one, we want to push $\\hat{x}_k$ as close as possible to one. The same if $x_k$ equals to zero.\n",
    "\n",
    "If the value is one, we just need to calculate the first part of the formula, that is, $- x_k log(\\hat{x}_k)$. Which, turns out to just calculate $- log(\\hat{x}_k)$.\n",
    "\n",
    "And if the value is zero, we need to calculate just the second part, $(1 - x_k) \\log (1 - \\hat{x}_k) \\ )$ - which turns out to be $log (1 - \\hat{x}_k) $.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Real values:</h3>\n",
    "$$l(f(x)) = - \\frac{1}{2}\\sum_{k} (\\hat{x}_k- x_k \\ )^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As the above function would behave badly with inputs that are not 0 or 1, we can use the sum of squared differences for our Loss function. If you use this loss function, it's necessary that you use a linear activation function for the output layer.\n",
    "\n",
    "As it was with the above example, $x_k$ is one of our inputs and $\\hat{x}_k$ is the respective output, and we want to make our output as similar as possible to our input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Loss Gradient:</h3>\n",
    "\n",
    "$$\\nabla_{\\hat{a}(x^{(t)})} \\ l( \\ f(x^{(t)}))  = \\hat{x}^{(t)} - x^{(t)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We use the gradient descent to reach the local minimum of our function $l( \\ f(x^{(t)})$, taking steps towards the negative of the gradient of the function in the current point.\n",
    "\n",
    "Our function about the gradient $(\\nabla_{\\hat{a}(x^{(t)})})$ of the loss of $l( \\ f(x^{(t)})$ in the preactivation of the output layer.\n",
    "\n",
    "It's actually a simple formula, it is done by calculating the difference between our output $\\hat{x}^{(t)}$ and our input $x^{(t)}$.\n",
    "\n",
    "Then our network backpropagates our gradient $\\nabla_{\\hat{a}(x^{(t)})} \\ l( \\ f(x^{(t)}))$ through the network using <b>backpropagation</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-63b75e990d9c>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../data/mnist/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, let's give the parameters that are going to be used by our NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_epochs = 20\n",
    "batch_size = 256\n",
    "display_step = 1\n",
    "examples_to_show = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer num features\n",
    "n_hidden_2 = 128 # 2nd layer num features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "\n",
    "# tf Graph input (only pictures)\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'encoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),\n",
    "    'decoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_input])),\n",
    "}\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'encoder_b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'decoder_b2': tf.Variable(tf.random_normal([n_input])),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we need to create our encoder. \n",
    "Sigmoidal functions delivers great results with this type of network. \n",
    "This is due to having a good derivative that is well-suited to backpropagation. \n",
    "Create our encoder using the sigmoidal function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Building the encoder\n",
    "def encoder(x):\n",
    "    # Encoder first layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n",
    "    # Encoder second layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And the decoder:\n",
    "\n",
    "You can see that the layer_1 in the encoder is the layer_2 in the decoder and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Building the decoder\n",
    "def decoder(x):\n",
    "    # Decoder first layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),biases['decoder_b1']))\n",
    "    # Decoder second layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's construct our model.\n",
    "In the variable <code>cost</code> we have the loss function and in the <code>optimizer</code> variable we have our gradient used for backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Construct model\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "# Reconstructed Images\n",
    "y_pred = decoder_op\n",
    "# Targets (Labels) are the input data.\n",
    "y_true = X\n",
    "\n",
    "# Define loss and optimizer, minimize the squared error\n",
    "cost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For training we will run for 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost= 0.199206784\n",
      "Epoch: 2 cost= 0.162534103\n",
      "Epoch: 3 cost= 0.145250902\n",
      "Epoch: 4 cost= 0.137110353\n",
      "Epoch: 5 cost= 0.133230001\n",
      "Epoch: 6 cost= 0.123301029\n",
      "Epoch: 7 cost= 0.117733181\n",
      "Epoch: 8 cost= 0.117027655\n",
      "Epoch: 9 cost= 0.109509446\n",
      "Epoch: 10 cost= 0.109413885\n",
      "Epoch: 11 cost= 0.105632201\n",
      "Epoch: 12 cost= 0.100575626\n",
      "Epoch: 13 cost= 0.099308178\n",
      "Epoch: 14 cost= 0.097329438\n",
      "Epoch: 15 cost= 0.094611712\n",
      "Epoch: 16 cost= 0.095629126\n",
      "Epoch: 17 cost= 0.094360776\n",
      "Epoch: 18 cost= 0.095305383\n",
      "Epoch: 19 cost= 0.092547573\n",
      "Epoch: 20 cost= 0.089663915\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "# Using InteractiveSession (more convenient while using Notebooks)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print(f\"Epoch: {epoch+1} cost= {c:.9f}\")\n",
    "\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, let's apply encoder and decoder for our tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Applying encode and decode over test set\n",
    "encode_decode = sess.run(\n",
    "    y_pred, feed_dict={X: mnist.test.images[:examples_to_show]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's simply visualize our graphs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare original images with their reconstructions\n",
    "f, a = plt.subplots(2, 10, figsize=(10, 2))\n",
    "for i in range(examples_to_show):\n",
    "    a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "    a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As you can see, the reconstructions were successful. It can be seen that some noise were added to the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Belief Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One problem with traditional multilayer perceptrons/artificial neural networks is that backpropagation can often lead to “local minima”. This is when your “error surface” contains multiple grooves and you fall into a groove that is not lowest possible groove as you perform gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Deep belief networks__ solve this problem by using an extra step called __pre-training__. Pre-training is done before backpropagation and can lead to an error rate not far from optimal. This puts us in the “neighborhood” of the final solution. Then we use backpropagation to slowly reduce the error rate from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "DBNs can be divided in two major parts. The first one are multiple layers of Restricted Boltzmann Machines (RBMs) to pre-train our network. The second one is a feed-forward backpropagation network, that will further refine the results from the RBM stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/15y15xs7w72eer0on3gbi8zu6835imru.png\" alt=\"DBN Model\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's begin by importing the necessary libraries and utilities functions to implement a Deep Belief Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#urllib is used to download the utils file from deeplearning.net\n",
    "\n",
    "# import urllib.request\n",
    "# with urllib.request.urlopen(\"http://deeplearning.net/tutorial/code/utils.py\") as url:\n",
    "#     response = url.read()\n",
    "# target = open('../utils/utils.py', 'w')\n",
    "# target.write(response.decode('utf-8'))\n",
    "# target.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../utils'))\n",
    "sys.path.insert(1, os.path.abspath('../utils/utils'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Import the math function for calculations\n",
    "import math\n",
    "#Tensorflow library. Used to implement machine learning models\n",
    "import tensorflow as tf\n",
    "#Numpy contains helpful functions for efficient mathematical calculations\n",
    "import numpy as np\n",
    "#Image library for image manipulation\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#import Image\n",
    "#Utils file\n",
    "import utils\n",
    "from utils import tile_raster_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Constructing the Layers of RBMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First of all, let's detail Restricted Boltzmann Machines.\n",
    "\n",
    "#### What are Restricted Boltzmann Machines?\n",
    "RBMs are shallow neural nets that learn to reconstruct data by themselves in an unsupervised fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### How it works?\n",
    "Simply, RBM takes the inputs and translates them to a set of numbers that represents them. Then, these numbers can be translated back to reconstruct the inputs. Through several forward and backward passes, the RBM will be trained, and a trained RBM can reveal which features are the most important ones when detecting patterns.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Why are RBMs important?\n",
    "It can automatically extract __meaningful__ features from a given input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What's the RBM's structure?\n",
    "It only possesses two layers; A visible input layer, and a hidden layer where the features are learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/7th91vjz32jhslacdym7ll3udq2zixjb.png\" alt=\"RBM Model\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To implement DBNs in TensorFlow, we will implement a class for the Restricted Boltzmann Machines (RBM). The class below implements an intuitive way of creating and using RBM's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class that defines the behavior of the RBM\n",
    "class RBM(object):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        #Defining the hyperparameters\n",
    "        self._input_size = input_size #Size of input\n",
    "        self._output_size = output_size #Size of output\n",
    "        self.epochs = 5 #Amount of training iterations\n",
    "        self.learning_rate = 1.0 #The step used in gradient descent\n",
    "        self.batchsize = 100 #The size of how much data will be used for training per sub iteration\n",
    "        \n",
    "        #Initializing weights and biases as matrices full of zeroes\n",
    "        self.w = np.zeros([input_size, output_size], np.float32) #Creates and initializes the weights with 0\n",
    "        self.hb = np.zeros([output_size], np.float32) #Creates and initializes the hidden biases with 0\n",
    "        self.vb = np.zeros([input_size], np.float32) #Creates and initializes the visible biases with 0\n",
    "\n",
    "\n",
    "    #Fits the result from the weighted visible layer plus the bias into a sigmoid curve\n",
    "    def prob_h_given_v(self, visible, w, hb):\n",
    "        #Sigmoid \n",
    "        return tf.nn.sigmoid(tf.matmul(visible, w) + hb)\n",
    "\n",
    "    #Fits the result from the weighted hidden layer plus the bias into a sigmoid curve\n",
    "    def prob_v_given_h(self, hidden, w, vb):\n",
    "        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)\n",
    "    \n",
    "    #Generate the sample probability\n",
    "    def sample_prob(self, probs):\n",
    "        return tf.nn.relu(tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n",
    "\n",
    "    #Training method for the model\n",
    "    def train(self, X):\n",
    "        #Create the placeholders for our parameters\n",
    "        _w = tf.placeholder(\"float\", [self._input_size, self._output_size])\n",
    "        _hb = tf.placeholder(\"float\", [self._output_size])\n",
    "        _vb = tf.placeholder(\"float\", [self._input_size])\n",
    "        \n",
    "        prv_w = np.zeros([self._input_size, self._output_size], np.float32) #Creates and initializes the weights with 0\n",
    "        prv_hb = np.zeros([self._output_size], np.float32) #Creates and initializes the hidden biases with 0\n",
    "        prv_vb = np.zeros([self._input_size], np.float32) #Creates and initializes the visible biases with 0\n",
    "\n",
    "        \n",
    "        cur_w = np.zeros([self._input_size, self._output_size], np.float32)\n",
    "        cur_hb = np.zeros([self._output_size], np.float32)\n",
    "        cur_vb = np.zeros([self._input_size], np.float32)\n",
    "        v0 = tf.placeholder(\"float\", [None, self._input_size])\n",
    "        \n",
    "        #Initialize with sample probabilities\n",
    "        h0 = self.sample_prob(self.prob_h_given_v(v0, _w, _hb))\n",
    "        v1 = self.sample_prob(self.prob_v_given_h(h0, _w, _vb))\n",
    "        h1 = self.prob_h_given_v(v1, _w, _hb)\n",
    "        \n",
    "        #Create the Gradients\n",
    "        positive_grad = tf.matmul(tf.transpose(v0), h0)\n",
    "        negative_grad = tf.matmul(tf.transpose(v1), h1)\n",
    "        \n",
    "        #Update learning rates for the layers\n",
    "        update_w = _w + self.learning_rate *(positive_grad - negative_grad) / tf.to_float(tf.shape(v0)[0])\n",
    "        update_vb = _vb +  self.learning_rate * tf.reduce_mean(v0 - v1, 0)\n",
    "        update_hb = _hb +  self.learning_rate * tf.reduce_mean(h0 - h1, 0)\n",
    "        \n",
    "        #Find the error rate\n",
    "        err = tf.reduce_mean(tf.square(v0 - v1))\n",
    "        \n",
    "        #Training loop\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            #For each epoch\n",
    "            for epoch in range(self.epochs):\n",
    "                #For each step/batch\n",
    "                for start, end in zip(range(0, len(X), self.batchsize),range(self.batchsize,len(X), self.batchsize)):\n",
    "                    batch = X[start:end]\n",
    "                    #Update the rates\n",
    "                    cur_w = sess.run(update_w, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    cur_hb = sess.run(update_hb, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    cur_vb = sess.run(update_vb, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    prv_w = cur_w\n",
    "                    prv_hb = cur_hb\n",
    "                    prv_vb = cur_vb\n",
    "                error = sess.run(err, feed_dict={v0: X, _w: cur_w, _vb: cur_vb, _hb: cur_hb})\n",
    "                print (f'Epoch: {epoch} reconstruction error: {error}')                \n",
    "            self.w = prv_w\n",
    "            self.hb = prv_hb\n",
    "            self.vb = prv_vb\n",
    "\n",
    "    #Create expected output for our DBN\n",
    "    def rbm_outpt(self, X):\n",
    "        input_X = tf.constant(X)\n",
    "        _w = tf.constant(self.w)\n",
    "        _hb = tf.constant(self.hb)\n",
    "        out = tf.nn.sigmoid(tf.matmul(input_X, _w) + _hb)\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            return sess.run(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will be using the MNIST dataset, which is a commonly used dataset used for model benchmarking comprised of handwritten digits. We will import the images using \"One Hot Encoding\" to encode the handwritten images into values varying from 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/1yvz587r3jot1n8itvqqbcivv3ay40qh.png\" alt=\"MNIST\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Getting the MNIST data provided by Tensorflow\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#Loading in the mnist data\n",
    "mnist = input_data.read_data_sets(\"../data/mnist/\", one_hot=True)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images,\\\n",
    "    mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating the Deep Belief Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With the RBM class created and MNIST Datasets loaded in, we can start creating the DBN. For our example, we are going to use a 3 RBMs, one with 500 hidden units, the second one with 200 and the last one with 50. We are generating a **deep hierarchical representation of the training data**. The cell below accomplishes this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBM:  0   784 -> 500\n",
      "RBM:  1   500 -> 200\n",
      "RBM:  2   200 -> 50\n"
     ]
    }
   ],
   "source": [
    "RBM_hidden_sizes = [500, 200 , 50 ] #create 2 layers of RBM with size 400 and 100\n",
    "\n",
    "#Since we are training, set input as training data\n",
    "inpX = trX\n",
    "\n",
    "#Create list to hold our RBMs\n",
    "rbm_list = []\n",
    "\n",
    "#Size of inputs is the number of inputs in the training set\n",
    "input_size = inpX.shape[1]\n",
    "\n",
    "#For each RBM we want to generate\n",
    "for i, size in enumerate(RBM_hidden_sizes):\n",
    "    print ('RBM: ',i,' ',input_size,'->', size)\n",
    "    rbm_list.append(RBM(input_size, size))\n",
    "    input_size = size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RBM Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will now begin the pre-training step and train each of the RBMs in our stack by individiually calling the train function, getting the current RBMs output and using it as the next RBM's input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New RBM:\n",
      "WARNING:tensorflow:From <ipython-input-14-54545e7f9a3d>:58: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "Epoch: 0 reconstruction error: 0.059699781239032745\n",
      "Epoch: 1 reconstruction error: 0.05231033265590668\n",
      "Epoch: 2 reconstruction error: 0.04890792444348335\n",
      "Epoch: 3 reconstruction error: 0.04741987958550453\n",
      "Epoch: 4 reconstruction error: 0.045524962246418\n",
      "New RBM:\n",
      "Epoch: 0 reconstruction error: 0.03518270328640938\n",
      "Epoch: 1 reconstruction error: 0.03080902248620987\n",
      "Epoch: 2 reconstruction error: 0.02894127182662487\n",
      "Epoch: 3 reconstruction error: 0.02752990461885929\n",
      "Epoch: 4 reconstruction error: 0.026972386986017227\n",
      "New RBM:\n",
      "Epoch: 0 reconstruction error: 0.05804537609219551\n",
      "Epoch: 1 reconstruction error: 0.054871778935194016\n",
      "Epoch: 2 reconstruction error: 0.05316389724612236\n",
      "Epoch: 3 reconstruction error: 0.0530136376619339\n",
      "Epoch: 4 reconstruction error: 0.052518513053655624\n"
     ]
    }
   ],
   "source": [
    "#For each RBM in our list\n",
    "for rbm in rbm_list:\n",
    "    print ('New RBM:')\n",
    "    #Train a new one\n",
    "    rbm.train(inpX) \n",
    "    #Return the output layer\n",
    "    inpX = rbm.rbm_outpt(inpX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can convert the learned representation of input data into a supervised prediction, e.g. a linear classifier. Specifically, we use the output of the last hidden layer of the DBN to classify digits using a shallow Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The class below implements the Neural Network that makes use of the pre-trained RBMs from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class NN(object):\n",
    "    \n",
    "    def __init__(self, sizes, X, Y):\n",
    "        #Initialize hyperparameters\n",
    "        self._sizes = sizes\n",
    "        self._X = X\n",
    "        self._Y = Y\n",
    "        self.w_list = []\n",
    "        self.b_list = []\n",
    "        self._learning_rate =  1.0\n",
    "        self._momentum = 0.0\n",
    "        self._epoches = 10\n",
    "        self._batchsize = 100\n",
    "        input_size = X.shape[1]\n",
    "        \n",
    "        #initialization loop\n",
    "        for size in self._sizes + [Y.shape[1]]:\n",
    "            #Define upper limit for the uniform distribution range\n",
    "            max_range = 4 * math.sqrt(6. / (input_size + size))\n",
    "            \n",
    "            #Initialize weights through a random uniform distribution\n",
    "            self.w_list.append(\n",
    "                np.random.uniform( -max_range, max_range, [input_size, size]).astype(np.float32))\n",
    "            \n",
    "            #Initialize bias as zeroes\n",
    "            self.b_list.append(np.zeros([size], np.float32))\n",
    "            input_size = size\n",
    "      \n",
    "    #load data from rbm\n",
    "    def load_from_rbms(self, dbn_sizes,rbm_list):\n",
    "        #Check if expected sizes are correct\n",
    "        assert len(dbn_sizes) == len(self._sizes)\n",
    "        \n",
    "        for i in range(len(self._sizes)):\n",
    "            #Check if for each RBN the expected sizes are correct\n",
    "            assert dbn_sizes[i] == self._sizes[i]\n",
    "        \n",
    "        #If everything is correct, bring over the weights and biases\n",
    "        for i in range(len(self._sizes)):\n",
    "            self.w_list[i] = rbm_list[i].w\n",
    "            self.b_list[i] = rbm_list[i].hb\n",
    "\n",
    "    #Training method\n",
    "    def train(self):\n",
    "        #Create placeholders for input, weights, biases, output\n",
    "        _a = [None] * (len(self._sizes) + 2)\n",
    "        _w = [None] * (len(self._sizes) + 1)\n",
    "        _b = [None] * (len(self._sizes) + 1)\n",
    "        _a[0] = tf.placeholder(\"float\", [None, self._X.shape[1]])\n",
    "        y = tf.placeholder(\"float\", [None, self._Y.shape[1]])\n",
    "        \n",
    "        #Define variables and activation functoin\n",
    "        for i in range(len(self._sizes) + 1):\n",
    "            _w[i] = tf.Variable(self.w_list[i])\n",
    "            _b[i] = tf.Variable(self.b_list[i])\n",
    "        for i in range(1, len(self._sizes) + 2):\n",
    "            _a[i] = tf.nn.sigmoid(tf.matmul(_a[i - 1], _w[i - 1]) + _b[i - 1])\n",
    "        \n",
    "        #Define the cost function\n",
    "        cost = tf.reduce_mean(tf.square(_a[-1] - y))\n",
    "        \n",
    "        #Define the training operation (Momentum Optimizer minimizing the Cost function)\n",
    "        train_op = tf.train.MomentumOptimizer(self._learning_rate, self._momentum).minimize(cost)\n",
    "        \n",
    "        #Prediction operation\n",
    "        predict_op = tf.argmax(_a[-1], 1)\n",
    "        \n",
    "        #Training Loop\n",
    "        with tf.Session() as sess:\n",
    "            #Initialize Variables\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            #For each epoch\n",
    "            for i in range(self._epoches):\n",
    "                \n",
    "                #For each step\n",
    "                for start, end in zip(range(0, len(self._X), self._batchsize), range(self._batchsize, len(self._X), self._batchsize)):\n",
    "                    \n",
    "                    #Run the training operation on the input data\n",
    "                    sess.run(train_op, feed_dict={ _a[0]: self._X[start:end], y: self._Y[start:end]})\n",
    "                \n",
    "                for j in range(len(self._sizes) + 1):\n",
    "                    #Retrieve weights and biases\n",
    "                    self.w_list[j] = sess.run(_w[j])\n",
    "                    self.b_list[j] = sess.run(_b[j])\n",
    "                \n",
    "                print (\"Accuracy rating for epoch \" + str(i) + \": \" + str(np.mean(np.argmax(self._Y, axis=1) == sess.run(predict_op, feed_dict={_a[0]: self._X, y: self._Y}))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's execute our code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rating for epoch 0: 0.5035454545454545\n",
      "Accuracy rating for epoch 1: 0.6314727272727273\n",
      "Accuracy rating for epoch 2: 0.7189090909090909\n",
      "Accuracy rating for epoch 3: 0.8031636363636364\n",
      "Accuracy rating for epoch 4: 0.8648181818181818\n",
      "Accuracy rating for epoch 5: 0.8874909090909091\n",
      "Accuracy rating for epoch 6: 0.8992727272727272\n",
      "Accuracy rating for epoch 7: 0.9063818181818182\n",
      "Accuracy rating for epoch 8: 0.9115272727272727\n",
      "Accuracy rating for epoch 9: 0.9159454545454545\n"
     ]
    }
   ],
   "source": [
    "nNet = NN(RBM_hidden_sizes, trX, trY)\n",
    "nNet.load_from_rbms(RBM_hidden_sizes,rbm_list)\n",
    "nNet.train()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
